{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    49 loss: 2.11915588\n",
      "epoch:    99 loss: 1.91145945\n",
      "epoch:   149 loss: 1.59551179\n",
      "epoch:   199 loss: 1.30557978\n",
      "epoch:   249 loss: 0.83712041\n",
      "epoch:   299 loss: 0.44223481\n",
      "epoch:   349 loss: 0.23533925\n",
      "epoch:   399 loss: 0.18482254\n",
      "epoch:   449 loss: 0.15834740\n",
      "epoch:   499 loss: 0.12690689\n",
      "epoch:   549 loss: 0.10768117\n",
      "epoch:   599 loss: 0.09146193\n",
      "epoch:   649 loss: 0.07611272\n",
      "epoch:   699 loss: 0.06163306\n",
      "epoch:   749 loss: 0.05000074\n",
      "epoch:   799 loss: 0.04207223\n",
      "epoch:   849 loss: 0.03593241\n",
      "epoch:   899 loss: 0.02983493\n",
      "epoch:   949 loss: 0.02509461\n",
      "epoch:   999 loss: 0.02161570\n"
     ]
    }
   ],
   "source": [
    "# solve after 40s of training 5000/128\n",
    "# default_maze = torch.tensor([\n",
    "#     [1, 0, 0, 0, 0],\n",
    "#     [1, 1, 1, 1, 1],\n",
    "#     [0, 1, 0, 1, 0],\n",
    "#     [1, 1, 0, 0, 0],\n",
    "#     [1, 1, 1, 1, -1],\n",
    "# ])\n",
    "\n",
    "default_maze = torch.tensor([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, -1],\n",
    "])\n",
    "\n",
    "# default_maze = torch.tensor([\n",
    "#     [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     [0, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "#     [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "#     [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "#     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    "#     [0, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
    "#     [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "#     [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "#     [0, 0, 0, 0, 1, 1, 1, 1, 1, -1],\n",
    "# ])\n",
    "\n",
    "# doesn't solve even after 2h of training 100000/512\n",
    "# default_maze = torch.tensor([\n",
    "#     [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    "#     [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
    "#     [1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0],\n",
    "#     [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "#     [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "#     [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
    "#     [1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
    "#     [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0],\n",
    "#     [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
    "#     [0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
    "#     [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "#     [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "#     [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0],\n",
    "#     [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
    "#     [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, -1],\n",
    "# ])\n",
    "MAZE_WIDTH = default_maze.shape[0]\n",
    "INPUT_SIZE = MAZE_WIDTH * MAZE_WIDTH + 2 * MAZE_WIDTH\n",
    "MOVES = {\n",
    "    (-1, 0): torch.tensor(0).to(device), # up\n",
    "    (1, 0):  torch.tensor(1).to(device), # down\n",
    "    (0, -1): torch.tensor(2).to(device), # left\n",
    "    (0, 1):  torch.tensor(3).to(device),  # right\n",
    " }\n",
    "\n",
    "# policy\n",
    "HIT_WALL_PENALTY = -1\n",
    "MOVE_PENALTY = 0\n",
    "WIN_REWARD = 10\n",
    " \n",
    "# hyperparams\n",
    "# BATCH_SIZE = 128\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 512\n",
    "# EPOCH = 100000\n",
    "# EPOCH = 5000\n",
    "LEARNING_RATE = 3e-4\n",
    "\n",
    "def get_maze():\n",
    "    maze = default_maze\n",
    "    rewards = torch.zeros_like(maze)\n",
    "    rewards[maze == 0] = HIT_WALL_PENALTY\n",
    "    rewards[maze == 1] = MOVE_PENALTY\n",
    "    rewards[maze == -1] = WIN_REWARD\n",
    "    return maze, rewards\n",
    "\n",
    "def get_reward(rewards, pos):\n",
    "    x, y = pos\n",
    "    a, b = rewards.shape\n",
    "    if 0 <= x < a and 0 <= y < b:\n",
    "        return rewards[x, y]\n",
    "    return HIT_WALL_PENALTY\n",
    "\n",
    "# random edition\n",
    "def get_next_pos(maze, rewards, pos):\n",
    "    new_pos = pos # default to bouncing off a wall.\n",
    "    reward = HIT_WALL_PENALTY # default to hitting a wall.\n",
    "    move = random.choice(list(MOVES.keys()))\n",
    "    x, y = pos\n",
    "    a, b = maze.shape\n",
    "    i, j = move\n",
    "    if 0 <= x + i < a and 0 <= y + j < b:\n",
    "        # if maze[x + i, y + j] != -1:\n",
    "        new_pos = (x + i, y + j)\n",
    "        reward = get_reward(rewards, new_pos)\n",
    "    return new_pos, reward, move\n",
    "\n",
    "def get_batch():\n",
    "    batch = []\n",
    "    maze, rewards = get_maze()\n",
    "    positions = random.choices((maze == 1).nonzero().tolist(), k=BATCH_SIZE)\n",
    "    for pos in positions:\n",
    "        new_pos, reward, move = get_next_pos(maze, rewards, pos)\n",
    "        batch.append((pos, move, new_pos, reward))\n",
    "    return maze, batch\n",
    "\n",
    "# cheating edition\n",
    "# def get_next_pos(maze, rewards, pos, move):\n",
    "#     new_pos = pos # default to bouncing off a wall.\n",
    "#     reward = HIT_WALL_PENALTY # default to hitting a wall.\n",
    "#     x, y = pos\n",
    "#     a, b = maze.shape\n",
    "#     i, j = move\n",
    "#     if 0 <= x + i < a and 0 <= y + j < b:\n",
    "#         # if maze[x + i, y + j] != -1:\n",
    "#         new_pos = (x + i, y + j)\n",
    "#         reward = get_reward(rewards, new_pos)\n",
    "#     return new_pos, reward, move\n",
    "\n",
    "\n",
    "# def get_batch():\n",
    "#     batch = []\n",
    "#     maze, rewards = get_maze()\n",
    "#     for pos in (maze == 1).nonzero().tolist():\n",
    "#     # for pos in positions:\n",
    "#         for mm in list(MOVES.keys()):\n",
    "#             new_pos, reward, move = get_next_pos(maze, rewards, pos, mm)\n",
    "#             batch.append((pos, move, new_pos, reward))\n",
    "#     return maze, batch\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, INPUT_SIZE),\n",
    "            nn.LayerNorm(INPUT_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(INPUT_SIZE, INPUT_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(INPUT_SIZE, INPUT_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(INPUT_SIZE, len(MOVES)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)        \n",
    "        return logits\n",
    "\n",
    "def to_input(maze, pos):\n",
    "    return torch.cat((\n",
    "        maze.view(-1),\n",
    "        F.one_hot(torch.tensor(pos), num_classes=MAZE_WIDTH).view(-1),\n",
    "    )).float().to(device)\n",
    "\n",
    "def train(model):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    losses = []\n",
    "    for epoch in range(EPOCH):\n",
    "        maze, batch = get_batch()\n",
    "\n",
    "        # train vectorized\n",
    "        # ----------------\n",
    "        xs, ms, ys, rs, nuke = [], [], [], [], []\n",
    "        for pos, move, new_pos, reward in batch:\n",
    "            xs.append(to_input(maze, pos))\n",
    "            ms.append(F.one_hot(MOVES[move], num_classes=len(MOVES)))\n",
    "            ys.append(to_input(maze, new_pos))\n",
    "            rs.append(reward)\n",
    "            nuke.append(0. if reward == -1 else 1.)\n",
    "\n",
    "        XS = torch.stack(xs).to(device)\n",
    "        MS = torch.stack(ms).to(device)\n",
    "        YS = torch.stack(ys).to(device)\n",
    "        RS = torch.tensor(rs).to(device).view(-1, 1)\n",
    "        NUKE = torch.tensor(nuke).to(device).view(-1, 1)\n",
    "        bellman_left = (model(XS) * MS).sum(dim=1, keepdim=True)\n",
    "        qqs = model(YS).max(dim=1, keepdim=True).values\n",
    "\n",
    "        decay = 0.9\n",
    "        bellman_right = RS + qqs * NUKE * decay\n",
    "        # bellman_right = RS + qqs * decay\n",
    "\n",
    "        # Bellman equation\n",
    "        # Q(m, p) = r + max(Q(m', p'))\n",
    "        loss = F.mse_loss(bellman_left, bellman_right)\n",
    "        losses.append(loss.item())\n",
    "        if epoch % 50 == 49:\n",
    "            print(f\"epoch: {epoch: 5} loss: {torch.tensor(losses).mean():.8f}\")\n",
    "            losses = []\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # train non-vectorized\n",
    "        # --------------------\n",
    "        # lefts, rights = [], []\n",
    "        # for pos, move, new_pos, reward in batch:\n",
    "        #     qs = model(to_input(maze, pos))\n",
    "        #     hot = F.one_hot(MOVES[move], num_classes=len(MOVES))\n",
    "        #     bellman_left = (qs * hot).sum()\n",
    "\n",
    "        #     new_q = model(to_input(maze, new_pos)).max()\n",
    "        #     bellman_right = reward + new_q\n",
    "\n",
    "        #     lefts.append(bellman_left)\n",
    "        #     rights.append(bellman_right)\n",
    "        \n",
    "        # bellman_left = torch.stack(lefts).to(device)\n",
    "        # bellman_right = torch.stack(rights).to(device)\n",
    "        # loss = F.mse_loss(bellman_left, bellman_right)\n",
    "        # losses.append(loss.item())\n",
    "        # if epoch % 50 == 0:\n",
    "        #     print(f\"epoch: {epoch: 5} loss: {torch.tensor(losses).mean():.8f}\")\n",
    "        #     losses = []\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1,  1,  1,  1],\n",
      "        [ 0,  0,  0,  0,  1],\n",
      "        [ 1,  1,  1,  1,  1],\n",
      "        [ 1,  0,  0,  0,  0],\n",
      "        [ 1,  1,  1,  1, -1]])\n",
      "qs=tensor([-0.9896, -0.9845, -1.0054, -0.4615], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (0, 0) to (0, 1)\n",
      "qs=tensor([-0.9859, -1.0383, -0.4594, -0.4559], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (0, 1) to (0, 2)\n",
      "qs=tensor([-0.9892, -0.9905, -0.4358, -0.4194], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (0, 2) to (0, 3)\n",
      "qs=tensor([-1.0320, -0.9878, -0.4463, -0.4317], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (0, 3) to (0, 4)\n",
      "qs=tensor([-0.9468, -0.3659, -0.4057, -0.9038], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (1, 0) from (0, 4) to (1, 4)\n",
      "qs=tensor([-0.3306, -0.2177, -0.9767, -1.0120], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (1, 0) from (1, 4) to (2, 4)\n",
      "qs=tensor([-0.3475, -0.7748,  0.1226, -1.0165], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, -1) from (2, 4) to (2, 3)\n",
      "qs=tensor([-1.0042, -1.0698,  0.5438, -0.0053], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, -1) from (2, 3) to (2, 2)\n",
      "qs=tensor([-1.0182, -1.0110,  1.1002,  0.5180], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, -1) from (2, 2) to (2, 1)\n",
      "qs=tensor([-1.0109, -1.0012,  1.6757,  0.9984], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, -1) from (2, 1) to (2, 0)\n",
      "qs=tensor([-0.9778,  2.2659, -0.9935,  1.5119], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (1, 0) from (2, 0) to (3, 0)\n",
      "qs=tensor([ 2.0482,  2.8559, -0.9931, -1.0109], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (1, 0) from (3, 0) to (4, 0)\n",
      "qs=tensor([ 2.5607, -1.0032, -0.9988,  3.4625], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (4, 0) to (4, 1)\n",
      "qs=tensor([-1.0093, -1.0138,  3.0924,  4.1234], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (4, 1) to (4, 2)\n",
      "qs=tensor([-0.9889, -1.0162,  3.7675,  4.8430], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (4, 2) to (4, 3)\n",
      "qs=tensor([-1.0164, -0.9786,  4.3352,  5.5525], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "chose (0, 1) from (4, 3) to (4, 4)\n",
      "WIN\n"
     ]
    }
   ],
   "source": [
    "i2move = {i.detach().item(): v for v, i in MOVES.items()}\n",
    "\n",
    "def play(model, maze, pos=(0, 0)):\n",
    "    print(maze)\n",
    "    depth = 1000\n",
    "    while True:\n",
    "        qs = model(to_input(maze, pos))\n",
    "        print(f'{qs=}')\n",
    "        move = i2move[qs.argmax().tolist()]\n",
    "        new_pos = (pos[0] + move[0], pos[1] + move[1])\n",
    "        print(f'chose {move} from {pos} to {new_pos}')\n",
    "        if 0 <= new_pos[0] < MAZE_WIDTH and 0 <= new_pos[1] < MAZE_WIDTH:\n",
    "            pos = new_pos\n",
    "            if maze[pos] == -1:\n",
    "                print(\"WIN\")\n",
    "                break\n",
    "            elif maze[pos] == 0:\n",
    "                print(\"LOSE: HIT WALL\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"LOSE: OUTSIDE MAZE\")\n",
    "            break\n",
    "        depth -= 1\n",
    "        if depth == 0:\n",
    "            print(\"LOSE: TOO DEEP\")\n",
    "            break\n",
    "\n",
    "play(model, default_maze, pos=(0, 0))\n",
    "\n",
    "# print(default_maze)\n",
    "# for i in range(4, -1, -1):\n",
    "#     qs = model(to_input(default_maze, (4, i)))\n",
    "#     print(f'{qs=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([4, 3], (0, -1), (4, 2), tensor(0))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in get_batch()[1] if x[0] == [4, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    49 loss: 0.00073226\n",
      "epoch:    99 loss: 0.00000463\n",
      "epoch:   149 loss: 0.00000003\n",
      "epoch:   199 loss: 0.00000000\n",
      "epoch:   249 loss: 0.00000000\n",
      "epoch:   299 loss: 0.00000000\n",
      "epoch:   349 loss: 0.00000000\n",
      "epoch:   399 loss: 0.00000000\n",
      "epoch:   449 loss: 0.00000000\n",
      "epoch:   499 loss: 0.00000000\n",
      "epoch:   549 loss: 0.00000000\n",
      "epoch:   599 loss: 0.00000000\n",
      "epoch:   649 loss: 0.00000000\n",
      "epoch:   699 loss: 0.00000000\n",
      "epoch:   749 loss: 0.00000000\n",
      "epoch:   799 loss: 0.00000000\n",
      "epoch:   849 loss: 0.00000000\n",
      "epoch:   899 loss: 0.00000000\n",
      "epoch:   949 loss: 0.00000000\n",
      "epoch:   999 loss: 0.00000000\n",
      "epoch:  1049 loss: 0.00000128\n",
      "epoch:  1099 loss: 0.00000006\n",
      "epoch:  1149 loss: 0.00000264\n",
      "epoch:  1199 loss: 0.00000004\n",
      "epoch:  1249 loss: 0.00000338\n",
      "epoch:  1299 loss: 0.00000145\n",
      "epoch:  1349 loss: 0.00000001\n",
      "epoch:  1399 loss: 0.00000307\n",
      "epoch:  1449 loss: 0.00000358\n",
      "epoch:  1499 loss: 0.00000002\n",
      "epoch:  1549 loss: 0.00000000\n",
      "epoch:  1599 loss: 0.00000831\n",
      "epoch:  1649 loss: 0.00000014\n",
      "epoch:  1699 loss: 0.00000000\n",
      "epoch:  1749 loss: 0.00000658\n",
      "epoch:  1799 loss: 0.00000282\n",
      "epoch:  1849 loss: 0.00000002\n",
      "epoch:  1899 loss: 0.00000012\n",
      "epoch:  1949 loss: 0.00000759\n",
      "epoch:  1999 loss: 0.00000332\n",
      "epoch:  2049 loss: 0.00000754\n",
      "epoch:  2099 loss: 0.00000319\n",
      "epoch:  2149 loss: 0.00000002\n",
      "epoch:  2199 loss: 0.00000000\n",
      "epoch:  2249 loss: 0.00001082\n",
      "epoch:  2299 loss: 0.00000299\n",
      "epoch:  2349 loss: 0.00000002\n",
      "epoch:  2399 loss: 0.00000000\n",
      "epoch:  2449 loss: 0.00001119\n",
      "epoch:  2499 loss: 0.00000744\n",
      "epoch:  2549 loss: 0.00000006\n",
      "epoch:  2599 loss: 0.00001321\n",
      "epoch:  2649 loss: 0.00000525\n",
      "epoch:  2699 loss: 0.00000353\n",
      "epoch:  2749 loss: 0.00000532\n",
      "epoch:  2799 loss: 0.00000100\n",
      "epoch:  2849 loss: 0.00000845\n",
      "epoch:  2899 loss: 0.00000641\n",
      "epoch:  2949 loss: 0.00000754\n",
      "epoch:  2999 loss: 0.00000231\n",
      "epoch:  3049 loss: 0.00001207\n",
      "epoch:  3099 loss: 0.00000018\n",
      "epoch:  3149 loss: 0.00000058\n",
      "epoch:  3199 loss: 0.00001308\n",
      "epoch:  3249 loss: 0.00001133\n",
      "epoch:  3299 loss: 0.00000025\n",
      "epoch:  3349 loss: 0.00000001\n",
      "epoch:  3399 loss: 0.00001763\n",
      "epoch:  3449 loss: 0.00000036\n",
      "epoch:  3499 loss: 0.00001138\n",
      "epoch:  3549 loss: 0.00000043\n",
      "epoch:  3599 loss: 0.00000000\n",
      "epoch:  3649 loss: 0.00002621\n",
      "epoch:  3699 loss: 0.00000592\n",
      "epoch:  3749 loss: 0.00000938\n",
      "epoch:  3799 loss: 0.00000126\n",
      "epoch:  3849 loss: 0.00000006\n",
      "epoch:  3899 loss: 0.00000419\n",
      "epoch:  3949 loss: 0.00000540\n",
      "epoch:  3999 loss: 0.00000058\n",
      "epoch:  4049 loss: 0.00001109\n",
      "epoch:  4099 loss: 0.00000494\n",
      "epoch:  4149 loss: 0.00000033\n",
      "epoch:  4199 loss: 0.00001077\n",
      "epoch:  4249 loss: 0.00000907\n",
      "epoch:  4299 loss: 0.00000012\n",
      "epoch:  4349 loss: 0.00001096\n",
      "epoch:  4399 loss: 0.00000512\n",
      "epoch:  4449 loss: 0.00000085\n",
      "epoch:  4499 loss: 0.00000748\n",
      "epoch:  4549 loss: 0.00000156\n",
      "epoch:  4599 loss: 0.00000938\n",
      "epoch:  4649 loss: 0.00000341\n",
      "epoch:  4699 loss: 0.00000407\n",
      "epoch:  4749 loss: 0.00001564\n",
      "epoch:  4799 loss: 0.00000071\n",
      "epoch:  4849 loss: 0.00000003\n",
      "epoch:  4899 loss: 0.00002006\n",
      "epoch:  4949 loss: 0.00000045\n",
      "epoch:  4999 loss: 0.00000001\n",
      "epoch:  5049 loss: 0.00001458\n",
      "epoch:  5099 loss: 0.00000048\n",
      "epoch:  5149 loss: 0.00000340\n",
      "epoch:  5199 loss: 0.00001142\n",
      "epoch:  5249 loss: 0.00000006\n",
      "epoch:  5299 loss: 0.00001861\n",
      "epoch:  5349 loss: 0.00000099\n",
      "epoch:  5399 loss: 0.00000001\n",
      "epoch:  5449 loss: 0.00000016\n",
      "epoch:  5499 loss: 0.00001566\n",
      "epoch:  5549 loss: 0.00000012\n",
      "epoch:  5599 loss: 0.00001044\n",
      "epoch:  5649 loss: 0.00000063\n",
      "epoch:  5699 loss: 0.00000007\n",
      "epoch:  5749 loss: 0.00001393\n",
      "epoch:  5799 loss: 0.00000017\n",
      "epoch:  5849 loss: 0.00001151\n",
      "epoch:  5899 loss: 0.00000021\n",
      "epoch:  5949 loss: 0.00000002\n",
      "epoch:  5999 loss: 0.00002461\n",
      "epoch:  6049 loss: 0.00000032\n",
      "epoch:  6099 loss: 0.00000466\n",
      "epoch:  6149 loss: 0.00000890\n",
      "epoch:  6199 loss: 0.00000005\n",
      "epoch:  6249 loss: 0.00000000\n",
      "epoch:  6299 loss: 0.00001227\n",
      "epoch:  6349 loss: 0.00000686\n",
      "epoch:  6399 loss: 0.00000004\n",
      "epoch:  6449 loss: 0.00001204\n",
      "epoch:  6499 loss: 0.00000108\n",
      "epoch:  6549 loss: 0.00000599\n",
      "epoch:  6599 loss: 0.00000007\n",
      "epoch:  6649 loss: 0.00001147\n",
      "epoch:  6699 loss: 0.00000063\n",
      "epoch:  6749 loss: 0.00000863\n",
      "epoch:  6799 loss: 0.00000006\n",
      "epoch:  6849 loss: 0.00001517\n",
      "epoch:  6899 loss: 0.00000141\n",
      "epoch:  6949 loss: 0.00000966\n",
      "epoch:  6999 loss: 0.00000297\n",
      "epoch:  7049 loss: 0.00000002\n",
      "epoch:  7099 loss: 0.00000002\n",
      "epoch:  7149 loss: 0.00003075\n",
      "epoch:  7199 loss: 0.00000043\n",
      "epoch:  7249 loss: 0.00000000\n",
      "epoch:  7299 loss: 0.00000230\n",
      "epoch:  7349 loss: 0.00001045\n",
      "epoch:  7399 loss: 0.00000005\n",
      "epoch:  7449 loss: 0.00000017\n",
      "epoch:  7499 loss: 0.00001050\n",
      "epoch:  7549 loss: 0.00000011\n",
      "epoch:  7599 loss: 0.00001573\n",
      "epoch:  7649 loss: 0.00000033\n",
      "epoch:  7699 loss: 0.00000001\n",
      "epoch:  7749 loss: 0.00001375\n",
      "epoch:  7799 loss: 0.00000030\n",
      "epoch:  7849 loss: 0.00000000\n",
      "epoch:  7899 loss: 0.00001448\n",
      "epoch:  7949 loss: 0.00000333\n",
      "epoch:  7999 loss: 0.00000899\n",
      "epoch:  8049 loss: 0.00000071\n",
      "epoch:  8099 loss: 0.00000001\n",
      "epoch:  8149 loss: 0.00001370\n",
      "epoch:  8199 loss: 0.00000075\n",
      "epoch:  8249 loss: 0.00000009\n",
      "epoch:  8299 loss: 0.00001789\n",
      "epoch:  8349 loss: 0.00000017\n",
      "epoch:  8399 loss: 0.00000034\n",
      "epoch:  8449 loss: 0.00001444\n",
      "epoch:  8499 loss: 0.00000009\n",
      "epoch:  8549 loss: 0.00000000\n",
      "epoch:  8599 loss: 0.00000229\n",
      "epoch:  8649 loss: 0.00001350\n",
      "epoch:  8699 loss: 0.00000843\n",
      "epoch:  8749 loss: 0.00000335\n",
      "epoch:  8799 loss: 0.00000003\n",
      "epoch:  8849 loss: 0.00000001\n",
      "epoch:  8899 loss: 0.00001517\n",
      "epoch:  8949 loss: 0.00000033\n",
      "epoch:  8999 loss: 0.00001442\n",
      "epoch:  9049 loss: 0.00000650\n",
      "epoch:  9099 loss: 0.00000003\n",
      "epoch:  9149 loss: 0.00000226\n",
      "epoch:  9199 loss: 0.00000676\n",
      "epoch:  9249 loss: 0.00000005\n",
      "epoch:  9299 loss: 0.00000764\n",
      "epoch:  9349 loss: 0.00001020\n",
      "epoch:  9399 loss: 0.00000022\n",
      "epoch:  9449 loss: 0.00000000\n",
      "epoch:  9499 loss: 0.00001518\n",
      "epoch:  9549 loss: 0.00000142\n",
      "epoch:  9599 loss: 0.00000844\n",
      "epoch:  9649 loss: 0.00000050\n",
      "epoch:  9699 loss: 0.00000000\n",
      "epoch:  9749 loss: 0.00000796\n",
      "epoch:  9799 loss: 0.00000472\n",
      "epoch:  9849 loss: 0.00000051\n",
      "epoch:  9899 loss: 0.00001090\n",
      "epoch:  9949 loss: 0.00000032\n",
      "epoch:  9999 loss: 0.00001178\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NeuralNetwork:\n\tMissing key(s) in state_dict: \"linear_relu_stack.2.weight\", \"linear_relu_stack.2.bias\", \"linear_relu_stack.4.weight\", \"linear_relu_stack.4.bias\", \"linear_relu_stack.6.weight\", \"linear_relu_stack.6.bias\". \n\tUnexpected key(s) in state_dict: \"linear_relu_stack.7.weight\", \"linear_relu_stack.7.bias\", \"linear_relu_stack.1.weight\", \"linear_relu_stack.1.bias\", \"linear_relu_stack.3.weight\", \"linear_relu_stack.3.bias\", \"linear_relu_stack.5.weight\", \"linear_relu_stack.5.bias\". \n\tsize mismatch for linear_relu_stack.0.weight: copying a param with shape torch.Size([323, 323]) from checkpoint, the shape in current model is torch.Size([35, 35]).\n\tsize mismatch for linear_relu_stack.0.bias: copying a param with shape torch.Size([323]) from checkpoint, the shape in current model is torch.Size([35]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\p\\Desktop\\_ML\\rl\\q-learning_maze.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p/Desktop/_ML/rl/q-learning_maze.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# backup to disk\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p/Desktop/_ML/rl/q-learning_maze.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# torch.save(model.state_dict(), 'default-maze.pt')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p/Desktop/_ML/rl/q-learning_maze.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m m \u001b[39m=\u001b[39m NeuralNetwork()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/p/Desktop/_ML/rl/q-learning_maze.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m m\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mbigger-maze.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NeuralNetwork:\n\tMissing key(s) in state_dict: \"linear_relu_stack.2.weight\", \"linear_relu_stack.2.bias\", \"linear_relu_stack.4.weight\", \"linear_relu_stack.4.bias\", \"linear_relu_stack.6.weight\", \"linear_relu_stack.6.bias\". \n\tUnexpected key(s) in state_dict: \"linear_relu_stack.7.weight\", \"linear_relu_stack.7.bias\", \"linear_relu_stack.1.weight\", \"linear_relu_stack.1.bias\", \"linear_relu_stack.3.weight\", \"linear_relu_stack.3.bias\", \"linear_relu_stack.5.weight\", \"linear_relu_stack.5.bias\". \n\tsize mismatch for linear_relu_stack.0.weight: copying a param with shape torch.Size([323, 323]) from checkpoint, the shape in current model is torch.Size([35, 35]).\n\tsize mismatch for linear_relu_stack.0.bias: copying a param with shape torch.Size([323]) from checkpoint, the shape in current model is torch.Size([35])."
     ]
    }
   ],
   "source": [
    "# backup to disk\n",
    "# torch.save(model.state_dict(), 'default-maze.pt')\n",
    "\n",
    "# m = NeuralNetwork()\n",
    "# m.load_state_dict(torch.load('bigger-maze.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
