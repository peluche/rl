{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U gymnasium\n",
    "# %pip install -U gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REINFORCE â†’ REward Increment = Nonnegative Factor x Offset Reinforcement x Characteristic Eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-4\n",
    "GAMMA = 0.9\n",
    "MAX_STEPS = 1000\n",
    "N_HIDDEN = 32\n",
    "EPS = torch.finfo(torch.float32).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden=N_HIDDEN):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy(n_in=4, n_out=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\t loss: -0.15680313110351562\t episode length: 204\n",
      "  100\t loss: 4.316961288452148\t episode length: 243\n",
      "  200\t loss: -3.5299015045166016\t episode length: 448\n",
      "  300\t loss: 0.8699855804443359\t episode length: 177\n",
      "  400\t loss: 1.109283447265625\t episode length: 244\n",
      "  500\t loss: 2.2702207565307617\t episode length: 146\n",
      "  600\t loss: 1.0176544189453125\t episode length: 473\n",
      "  700\t loss: 2.59304141998291\t episode length: 262\n",
      "  800\t loss: -3.7774438858032227\t episode length: 244\n",
      "  900\t loss: -13.899826049804688\t episode length: 406\n"
     ]
    }
   ],
   "source": [
    "def discount_rewards(rewards, gamma):\n",
    "    '''\n",
    "    Compute the discounted rewards backwards through time, e.g.\n",
    "      r0 + gamma * (r1 + gamma * (r2 + gamma * (...)))\n",
    "      [----------------------------------------------]\n",
    "         ^         [---------------------------------]\n",
    "         |           ^           [-------------------]\n",
    "      discount[0]    |             ^           [-----]\n",
    "                  discount[1]      |             ^\n",
    "                                discount[2]      |\n",
    "                                              discount[n]                                              \n",
    "    '''\n",
    "    reward = 0\n",
    "    discounted_rewards = []\n",
    "    for r in rewards[::-1]:\n",
    "        reward = r + gamma * reward\n",
    "        discounted_rewards.append(reward)\n",
    "    return torch.tensor(discounted_rewards[::-1]).to(device)\n",
    "\n",
    "def train(model, epochs=10, lr=LR, gamma=GAMMA, max_steps=MAX_STEPS, log_every=100):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    opt = optim.Adam(policy.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        rewards, log_probs = [], []\n",
    "        state, _ = env.reset()\n",
    "        # forward pass\n",
    "        for t in range(MAX_STEPS):\n",
    "            # this feel bad performance wise, 1 cycle GPU, 1 cycle CPU\n",
    "            # it's too much context switching\n",
    "            # how can I benchmark this in a notebook?\n",
    "            actions = policy(torch.tensor(state).float().to(device))\n",
    "            action = torch.multinomial(actions, 1)\n",
    "            state, reward, done, _, _ = env.step(action.item())\n",
    "            rewards.append(reward)\n",
    "            log_probs.append(torch.log(actions[action]))\n",
    "            if done:\n",
    "                break\n",
    "        # backward pass\n",
    "        losses = []\n",
    "        discounted_rewards = discount_rewards(rewards, gamma)\n",
    "        normalized_discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + EPS)\n",
    "        for log_prob, reward in zip(log_probs, normalized_discounted_rewards):\n",
    "            losses.append(-log_prob * reward)\n",
    "        loss = torch.stack(losses).sum()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch % log_every == 0:\n",
    "            print(f'{epoch:5}\\t loss: {loss.item()}\\t episode length: {t}')\n",
    "    model.eval()\n",
    "\n",
    "train(policy, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# ----\n",
    "# torch.save(policy.state_dict(), 'weights/cartpole-reinforce-2.pt')\n",
    "\n",
    "# load\n",
    "# ----\n",
    "# m = Policy(n_in=4, n_out=2).to(device)\n",
    "# m.load_state_dict(torch.load('weights/cartpole-reinforce.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 298 timesteps\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def show_play(env, policy, max_steps=MAX_STEPS):\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.axis('off')\n",
    "    state, _ = env.reset()\n",
    "    img = ax.imshow(env.render())\n",
    "    for t in range(max_steps):\n",
    "        actions = policy(torch.tensor(state).float().to(device))\n",
    "        action = actions.argmax()\n",
    "        state, _, done, _, _ = env.step(action.item())\n",
    "        img.set_data(env.render())\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t + 1))\n",
    "            break\n",
    "\n",
    "show_play(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the code in a bunch of functions to make the cProfile easier to read\n",
    "\n",
    "def gpu_world(model, arg):\n",
    "    return model(arg)\n",
    "\n",
    "def cpu_world_simulate_env(env, action):\n",
    "    return env.step(action.item())\n",
    "\n",
    "def cpu_world_get_action(actions, log_probs):\n",
    "    # Categorical seems dog slow\n",
    "    # --------------------------\n",
    "    # m = torch.distributions.Categorical(actions)\n",
    "    # action = m.sample()\n",
    "    # log_probs.append(m.log_prob(action))\n",
    "\n",
    "    # multinormal is faster\n",
    "    # ---------------------\n",
    "    # action = torch.multinomial(actions, 1)\n",
    "    # log_probs.append(torch.log(actions[action]))\n",
    "\n",
    "    # but they should be equivalent\n",
    "    # -----------------------------\n",
    "    # assert m.log_prob(action) - torch.log(actions[action]) < 0.001\n",
    "\n",
    "    # epsilon greedy with pytorch's random\n",
    "    # -------------------------------\n",
    "    # if torch.rand(1) < 0.2:\n",
    "    #     action = torch.randint(0, 2, (1,))[0]\n",
    "    # else:\n",
    "    #     action = actions.argmax()\n",
    "    # log_probs.append(torch.log(actions[action]))\n",
    "\n",
    "    # epsilon greedy with python's random\n",
    "    # -----------------------------------\n",
    "    if random.random() < 0.2:\n",
    "        action = torch.randint(0, 2, (1,))[0]\n",
    "    else:\n",
    "        action = actions.argmax()\n",
    "    log_probs.append(torch.log(actions[action]))\n",
    "\n",
    "    return action\n",
    "\n",
    "def cpu_world_sample(rewards, log_probs, env, actions):\n",
    "    action = cpu_world_get_action(actions, log_probs)\n",
    "\n",
    "    state, reward, done, _, _ = cpu_world_simulate_env(env, action)\n",
    "    rewards.append(reward)\n",
    "    return state, done\n",
    "\n",
    "def cpu_world_backward_pass(rewards, log_probs, gamma):\n",
    "    losses = []\n",
    "    discounted_rewards = discount_rewards(rewards, gamma)\n",
    "    normalized_discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + EPS)\n",
    "    for log_prob, reward in zip(log_probs, normalized_discounted_rewards):\n",
    "        losses.append(-log_prob * reward)\n",
    "    return losses\n",
    "\n",
    "def gpu_world_backward_pass(losses, opt):\n",
    "    loss = torch.stack(losses).to(device).sum()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss\n",
    "\n",
    "def train_for_profiling(model, epochs=100, lr=LR, gamma=GAMMA, max_steps=MAX_STEPS):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    opt = optim.Adam(policy.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        rewards, log_probs = [], []\n",
    "        state, _ = env.reset()\n",
    "        # forward pass\n",
    "        for _ in range(MAX_STEPS):\n",
    "            actions = gpu_world(policy, torch.tensor(state).float().to(device))\n",
    "            state, done = cpu_world_sample(rewards, log_probs, env, actions)\n",
    "            if done: break\n",
    "        # backward pass\n",
    "        losses = cpu_world_backward_pass(rewards, log_probs, gamma)\n",
    "        loss = gpu_world_backward_pass(losses, opt)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'{epoch:5} {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 -1.0809001922607422\n",
      "   10 1.9035100936889648\n",
      "   20 -0.7205734252929688\n",
      "   30 -0.15667247772216797\n",
      "   40 -2.5725440979003906\n",
      "   50 1.4350948333740234\n",
      "   60 -41.44963836669922\n",
      "   70 0.5656423568725586\n",
      "   80 -11.336851119995117\n",
      "   90 -2.0969085693359375\n",
      "         1519648 function calls (1391183 primitive calls) in 26.023 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.436    0.436   26.023   26.023 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:65(train_for_profiling)\n",
      "      100    0.002    0.000    9.703    0.097 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:58(gpu_world_backward_pass)\n",
      "      100    0.001    0.000    9.604    0.096 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:428(backward)\n",
      "      100    0.001    0.000    9.603    0.096 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:106(backward)\n",
      "      100    9.597    0.096    9.597    0.096 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "    25687    0.048    0.000    6.273    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:43(cpu_world_sample)\n",
      "    25687    0.028    0.000    6.190    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:3(gpu_world)\n",
      "154122/25687    0.317    0.000    6.162    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1494(_call_impl)\n",
      "    25687    0.062    0.000    6.058    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1237419200.py:11(forward)\n",
      "    25687    0.261    0.000    5.909    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215(forward)\n",
      "    25687    2.648    0.000    3.875    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:9(cpu_world_get_action)\n",
      "    51374    0.164    0.000    3.818    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:113(forward)\n",
      "    51374    3.592    0.000    3.592    0.000 {built-in method torch._C._nn.linear}\n",
      "    25687    0.036    0.000    2.347    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:6(cpu_world_simulate_env)\n",
      "    25895    2.021    0.000    2.021    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "    26497    1.800    0.000    1.800    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "      100    0.910    0.009    0.968    0.010 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:50(cpu_world_backward_pass)\n",
      "    25687    0.026    0.000    0.754    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:102(forward)\n",
      "    25687    0.028    0.000    0.728    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1446(relu)\n",
      "    25687    0.692    0.000    0.692    0.000 {built-in method torch.relu}\n",
      "    25687    0.025    0.000    0.682    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1481(forward)\n",
      "    25687    0.033    0.000    0.657    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1813(softmax)\n",
      "    25687    0.633    0.000    0.633    0.000 {built-in method torch.log}\n",
      "    25687    0.617    0.000    0.617    0.000 {method 'softmax' of 'torch._C._TensorBase' objects}\n",
      "    20613    0.521    0.000    0.521    0.000 {method 'argmax' of 'torch._C._TensorBase' objects}\n",
      "    25687    0.038    0.000    0.513    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:46(step)\n",
      "    25687    0.016    0.000    0.474    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:52(step)\n",
      "    25687    0.021    0.000    0.458    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:45(step)\n",
      "    25687    0.213    0.000    0.437    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:132(step)\n",
      "    25791    0.415    0.000    0.415    0.000 {built-in method torch.tensor}\n",
      "   154222    0.201    0.000    0.201    0.000 {built-in method torch._C._get_tracing_state}\n",
      "    25687    0.119    0.000    0.125    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\spaces\\discrete.py:94(contains)\n",
      "   128435    0.096    0.000    0.096    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1601(__getattr__)\n",
      "    25787    0.080    0.000    0.080    0.000 {built-in method numpy.array}\n",
      "      100    0.003    0.000    0.062    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:265(wrapper)\n",
      "     5074    0.062    0.000    0.062    0.000 {built-in method torch.randint}\n",
      "      100    0.001    0.000    0.051    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:29(_use_grad)\n",
      "      100    0.001    0.000    0.049    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:108(step)\n",
      "      100    0.002    0.000    0.042    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:231(adam)\n",
      "      100    0.003    0.000    0.039    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:396(_multi_tensor_adam)\n",
      "    25687    0.020    0.000    0.031    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:207(__iter__)\n",
      "      100    0.000    0.000    0.025    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:920(__iter__)\n",
      "      100    0.024    0.000    0.024    0.000 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "      100    0.023    0.000    0.023    0.000 {built-in method torch.stack}\n",
      "    25687    0.023    0.000    0.023    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "      100    0.007    0.000    0.022    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\3126631963.py:1(discount_rewards)\n",
      "   106849    0.018    0.000    0.018    0.000 {method 'append' of 'list' objects}\n",
      "    51474    0.015    0.000    0.015    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "    25687    0.013    0.000    0.013    0.000 {built-in method math.cos}\n",
      "      100    0.003    0.000    0.009    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:435(zero_grad)\n",
      "      200    0.001    0.000    0.008    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:491(__enter__)\n",
      "      200    0.000    0.000    0.007    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_ops.py:497(__call__)\n",
      "    25787    0.007    0.000    0.007    0.000 {built-in method builtins.iter}\n",
      "      200    0.007    0.000    0.007    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "      200    0.007    0.000    0.007    0.000 {built-in method torch._foreach_add_}\n",
      "    25687    0.006    0.000    0.006    0.000 {built-in method math.sin}\n",
      "26940/26934    0.006    0.000    0.006    0.000 {built-in method builtins.isinstance}\n",
      "      200    0.005    0.000    0.005    0.000 {built-in method torch._foreach_mul_}\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:65(reset)\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:58(reset)\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:53(reset)\n",
      "      100    0.001    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:50(_make_grads)\n",
      "      100    0.001    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:193(reset)\n",
      "      100    0.000    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:112(decorate_context)\n",
      "    26087    0.004    0.000    0.004    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "      200    0.002    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:495(__exit__)\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._foreach_add}\n",
      "    25687    0.004    0.000    0.004    0.000 {method 'random' of '_random.Random' objects}\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch.ones_like}\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._foreach_sqrt}\n",
      "      100    0.000    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:228(_cuda_graph_capture_health_check)\n",
      "      100    0.003    0.000    0.003    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
      "      100    0.002    0.000    0.003    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:20(_group_tensors_by_device_and_dtype)\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method torch._foreach_addcdiv_}\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method torch._foreach_addcmul_}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'std' of 'torch._C._TensorBase' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'uniform' of 'numpy.random._generator.Generator' objects}\n",
      "       10    0.000    0.000    0.003    0.000 {built-in method builtins.print}\n",
      "       20    0.000    0.000    0.003    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:610(write)\n",
      "      100    0.002    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:66(_init_group)\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method torch._foreach_div_}\n",
      "      100    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:94(is_available)\n",
      "       20    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:532(_schedule_flush)\n",
      "       10    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:243(schedule)\n",
      "      200    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_ops.py:286(__call__)\n",
      "       10    0.002    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\zmq\\sugar\\socket.py:545(send)\n",
      "      200    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:482(__init__)\n",
      "      100    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:489(<listcomp>)\n",
      "      200    0.002    0.000    0.002    0.000 {built-in method torch._ops.profiler.}\n",
      "      800    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:39(_get_value)\n",
      "      100    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:91(_nvml_based_avail)\n",
      "      100    0.000    0.000    0.001    0.000 <frozen os>:773(getenv)\n",
      "      100    0.000    0.000    0.001    0.000 <frozen _collections_abc>:771(get)\n",
      "      100    0.001    0.000    0.001    0.000 <frozen os>:674(__getitem__)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:494(<listcomp>)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:64(_default_to_fused_or_foreach)\n",
      "      416    0.001    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:149(__init__)\n",
      "      400    0.001    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:52(_dispatch_sqrt)\n",
      "      300    0.000    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\graphs.py:19(is_current_stream_capturing)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:490(<listcomp>)\n",
      "      100    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_isCurrentStreamCapturing}\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:141(clone)\n",
      "     1600    0.001    0.000    0.001    0.000 {built-in method torch.is_complex}\n",
      "      200    0.001    0.000    0.001    0.000 C:\\Python311\\Lib\\typing.py:338(inner)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:433(<listcomp>)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:48(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 <frozen os>:748(encodekey)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:24(<listcomp>)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:53(__enter__)\n",
      "      500    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:72(<genexpr>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:27(<lambda>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:434(<listcomp>)\n",
      "     2123    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "      420    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:942(__hash__)\n",
      "     1908    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:1102(is_scripting)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:435(<listcomp>)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:57(__exit__)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:436(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:87(_is_compiled)\n",
      "      500    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:268(<genexpr>)\n",
      "      624    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1039(to)\n",
      "      101    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "      6/1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:795(_apply)\n",
      "      100    0.000    0.000    0.000    0.000 <frozen os>:742(check_str)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:492(<listcomp>)\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch.zeros_like}\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "      400    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:27(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:46(_stack_if_compiling)\n",
      "      416    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "      900    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_utils.py:786(is_compiling)\n",
      "      420    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:14(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:169(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:98(_tensor_or_tensors_to_tuple)\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
      "      301    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\core.py:215(np_random)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:1185(is_alive)\n",
      "      122    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "      6/1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2269(train)\n",
      "      200    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "       20    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505(_is_master_process)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2059(parameters)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2084(named_parameters)\n",
      "       22    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2167(children)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1139(convert)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\core.py:121(reset)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2045(_named_members)\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1617(__setattr__)\n",
      "      200    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\jit\\__init__.py:89(annotate)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\utils.py:17(maybe_parse_reset_bounds)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:1118(_wait_for_tstate_lock)\n",
      "       22    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2176(named_children)\n",
      "      100    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:489(add_param_group)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:249(_optimizer_step_code)\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:127(_event_pipe)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:799(compute_should_use_set_data)\n",
      "     21/7    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2224(named_modules)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\parameter.py:8(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._nn._parse_to}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "       20    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:568(is_set)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch._has_compatible_shallow_copy_type}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:291(_patch_step_function)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2113(<lambda>)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\__future__.py:20(get_overwrite_module_params_on_conversion)\n",
      "        6    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x0000023F4E1E2520}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "def profile_train(model):\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    train_for_profiling(model)\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "    ps.print_stats()\n",
    "    return s.getvalue()\n",
    "\n",
    "profile_output = profile_train(policy)\n",
    "print(profile_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "actor = Actor(n_in=10, n_out=2)\n",
    "critic = Critic(n_in=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=100, lr=LR):\n",
    "    actor_opt = optim.Adam(actor.parameters(), lr=lr)\n",
    "    critic_opt = optim.Adam(critic.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action_probs = actor(torch.from_numpy(state).float())\n",
    "            action = torch.multinomial(action_probs, 1).item()\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            V_current = critic(torch.from_numpy(state).float())\n",
    "            V_next = critic(torch.from_numpy(next_state).float())\n",
    "\n",
    "            # Compute advantage and TD-target\n",
    "            advantage = reward + (1 - int(done)) * V_next - V_current\n",
    "            td_target = reward + (1 - int(done)) * V_next\n",
    "\n",
    "            # Update the critic\n",
    "            critic_loss = advantage.pow(2)\n",
    "            critic_opt.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_opt.step()\n",
    "\n",
    "            # Update the actor\n",
    "            actor_loss = -torch.log(action_probs[action]) * advantage.detach()\n",
    "            actor_opt.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_opt.step()\n",
    "\n",
    "            state = next_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
