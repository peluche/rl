{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U gymnasium\n",
    "# %pip install -U gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-4\n",
    "GAMMA = 0.9\n",
    "MAX_STEPS = 1000\n",
    "N_HIDDEN = 32\n",
    "EPS = torch.finfo(torch.float32).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden=N_HIDDEN):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy(n_in=4, n_out=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 140.72378540039062\n",
      "  100 389.76593017578125\n",
      "  200 562.3916015625\n",
      "  300 1522.986083984375\n",
      "  400 1174.462890625\n",
      "  500 1487.4931640625\n",
      "  600 782.4196166992188\n",
      "  700 301.91668701171875\n",
      "  800 1335.84375\n",
      "  900 1174.96826171875\n"
     ]
    }
   ],
   "source": [
    "def discount_rewards(rewards, gamma):\n",
    "    '''\n",
    "    Compute the discounted rewards backwards through time, e.g.\n",
    "      r0 + gamma * (r1 + gamma * (r2 + gamma * (...)))\n",
    "      [----------------------------------------------]\n",
    "         ^         [---------------------------------]\n",
    "         |           ^           [-------------------]\n",
    "      discount[0]    |             ^           [-----]\n",
    "                  discount[1]      |             ^\n",
    "                                discount[2]      |\n",
    "                                              discount[n]                                              \n",
    "    '''\n",
    "    reward = 0\n",
    "    discounted_rewards = []\n",
    "    for r in rewards[::-1]:\n",
    "        reward = r + gamma * reward\n",
    "        discounted_rewards.append(reward)\n",
    "    return torch.tensor(discounted_rewards[::-1]).to(device)\n",
    "\n",
    "def train(model, epochs=10, lr=LR, gamma=GAMMA, max_steps=MAX_STEPS, log_every=100):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    opt = optim.Adam(policy.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        rewards, log_probs = [], []\n",
    "        state, _ = env.reset()\n",
    "        # forward pass\n",
    "        for _ in range(MAX_STEPS):\n",
    "            # this feel bad performance wise, 1 cycle GPU, 1 cycle CPU\n",
    "            # it's too much context switching\n",
    "            # how can I benchmark this in a notebook?\n",
    "            actions = policy(torch.tensor(state).float().to(device))\n",
    "            m = torch.distributions.Categorical(actions)\n",
    "            action = m.sample()\n",
    "            state, reward, done, _, _ = env.step(action.item())\n",
    "            rewards.append(reward)\n",
    "            log_probs.append(m.log_prob(action))\n",
    "            if done:\n",
    "                break\n",
    "        # backward pass\n",
    "        losses = []\n",
    "        discounted_rewards = discount_rewards(rewards, gamma)\n",
    "        for log_prob, reward in zip(log_probs, discounted_rewards):\n",
    "            losses.append(-log_prob * reward)\n",
    "        loss = torch.stack(losses).sum()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch % log_every == 0:\n",
    "            print(f'{epoch:5} {loss.item()}')\n",
    "    model.eval()\n",
    "\n",
    "train(policy, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# ----\n",
    "# torch.save(policy.state_dict(), 'weights/cartpole-reinforce.pt')\n",
    "\n",
    "# load\n",
    "# ----\n",
    "# m = Policy(n_in=4, n_out=2).to(device)\n",
    "# m.load_state_dict(torch.load('weights/cartpole-reinforce.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 413 timesteps\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def show_play(env, policy, max_steps=MAX_STEPS):\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.axis('off')\n",
    "    state, _ = env.reset()\n",
    "    img = ax.imshow(env.render())\n",
    "    for t in range(max_steps):\n",
    "        actions = policy(torch.tensor(state).float().to(device))\n",
    "        action = actions.argmax()\n",
    "        state, _, done, _, _ = env.step(action.item())\n",
    "        img.set_data(env.render())\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t + 1))\n",
    "            break\n",
    "\n",
    "show_play(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_world(model, arg):\n",
    "    return model(arg)\n",
    "\n",
    "def cpu_world_simulate_env(env, action):\n",
    "    return env.step(action.item())\n",
    "\n",
    "def cpu_world_sample(rewards, log_probs, env, actions):\n",
    "    # Categorical seems dog slow\n",
    "    # --------------------------\n",
    "    # m = torch.distributions.Categorical(actions)\n",
    "    # action = m.sample()\n",
    "    # log_probs.append(m.log_prob(action))\n",
    "\n",
    "    # multinormal is faster\n",
    "    # ---------------------\n",
    "    action = torch.multinomial(actions, 1)\n",
    "    log_probs.append(torch.log(actions[action]))\n",
    "\n",
    "    # but they should be equivalent\n",
    "    # -----------------------------\n",
    "    # assert m.log_prob(action) - torch.log(actions[action]) < 0.001\n",
    "\n",
    "    state, reward, done, _, _ = cpu_world_simulate_env(env, action)\n",
    "    rewards.append(reward)\n",
    "    return state, done\n",
    "\n",
    "def cpu_world_backward_pass(rewards, log_probs, gamma):\n",
    "    losses = []\n",
    "    discounted_rewards = discount_rewards(rewards, gamma)\n",
    "    for log_prob, reward in zip(log_probs, discounted_rewards):\n",
    "        losses.append(-log_prob * reward)\n",
    "    return losses\n",
    "\n",
    "def gpu_world_backward_pass(losses, opt):\n",
    "    loss = torch.stack(losses).to(device).sum()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss\n",
    "\n",
    "def train_for_profiling(model, epochs=100, lr=LR, gamma=GAMMA, max_steps=MAX_STEPS):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    opt = optim.Adam(policy.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        rewards, log_probs = [], []\n",
    "        state, _ = env.reset()\n",
    "        # forward pass\n",
    "        for _ in range(MAX_STEPS):\n",
    "            actions = gpu_world(policy, torch.tensor(state).float().to(device))\n",
    "            state, done = cpu_world_sample(rewards, log_probs, env, actions)\n",
    "            if done: break\n",
    "        # backward pass\n",
    "        losses = cpu_world_backward_pass(rewards, log_probs, gamma)\n",
    "        loss = gpu_world_backward_pass(losses, opt)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'{epoch:5} {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 460.3211364746094\n",
      "   10 876.9637451171875\n",
      "   20 2149.50048828125\n",
      "   30 1836.753173828125\n",
      "   40 860.16259765625\n",
      "   50 827.0250244140625\n",
      "   60 645.49462890625\n",
      "   70 943.9664916992188\n",
      "   80 709.8850708007812\n",
      "   90 959.7178955078125\n",
      "         1011506 function calls (923806 primitive calls) in 24.364 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.274    0.274   24.364   24.364 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1234081644.py:41(train_for_profiling)\n",
      "      100    0.001    0.000    8.839    0.088 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1234081644.py:34(gpu_world_backward_pass)\n",
      "    17534    0.730    0.000    8.816    0.001 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1234081644.py:7(cpu_world_sample)\n",
      "      100    0.001    0.000    8.754    0.088 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:428(backward)\n",
      "      100    0.001    0.000    8.753    0.088 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:106(backward)\n",
      "      100    8.747    0.087    8.747    0.087 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "    17534    6.265    0.000    6.265    0.000 {built-in method torch.multinomial}\n",
      "    17534    0.020    0.000    4.190    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1234081644.py:1(gpu_world)\n",
      "105204/17534    0.216    0.000    4.171    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1494(_call_impl)\n",
      "    17534    0.043    0.000    4.097    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1237419200.py:11(forward)\n",
      "    17534    0.179    0.000    3.995    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215(forward)\n",
      "    35068    0.104    0.000    2.586    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:113(forward)\n",
      "    35068    2.445    0.000    2.445    0.000 {built-in method torch._C._nn.linear}\n",
      "    17534    0.028    0.000    1.465    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1234081644.py:4(cpu_world_simulate_env)\n",
      "    17742    1.158    0.000    1.158    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "    18344    1.082    0.000    1.082    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "      100    0.625    0.006    0.780    0.008 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1234081644.py:27(cpu_world_backward_pass)\n",
      "    17534    0.019    0.000    0.498    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:102(forward)\n",
      "    17534    0.019    0.000    0.479    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1446(relu)\n",
      "    17534    0.018    0.000    0.468    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1481(forward)\n",
      "    17534    0.455    0.000    0.455    0.000 {built-in method torch.relu}\n",
      "    17534    0.033    0.000    0.451    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1813(softmax)\n",
      "    17534    0.413    0.000    0.413    0.000 {method 'softmax' of 'torch._C._TensorBase' objects}\n",
      "    17534    0.027    0.000    0.356    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:46(step)\n",
      "    17534    0.349    0.000    0.349    0.000 {built-in method torch.log}\n",
      "    17534    0.011    0.000    0.329    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:52(step)\n",
      "    17534    0.015    0.000    0.317    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:45(step)\n",
      "    17534    0.146    0.000    0.302    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:132(step)\n",
      "    17638    0.297    0.000    0.297    0.000 {built-in method torch.tensor}\n",
      "   105304    0.136    0.000    0.136    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      100    0.000    0.000    0.132    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:920(__iter__)\n",
      "      100    0.131    0.001    0.131    0.001 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "    17534    0.084    0.000    0.088    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\spaces\\discrete.py:94(contains)\n",
      "    87670    0.062    0.000    0.062    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1601(__getattr__)\n",
      "      100    0.003    0.000    0.061    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:265(wrapper)\n",
      "    17634    0.055    0.000    0.055    0.000 {built-in method numpy.array}\n",
      "      100    0.001    0.000    0.050    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:29(_use_grad)\n",
      "      100    0.001    0.000    0.048    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:108(step)\n",
      "      100    0.002    0.000    0.041    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:231(adam)\n",
      "      100    0.003    0.000    0.038    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:396(_multi_tensor_adam)\n",
      "    17534    0.014    0.000    0.021    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:207(__iter__)\n",
      "      100    0.005    0.000    0.019    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\129573380.py:1(discount_rewards)\n",
      "    17534    0.016    0.000    0.016    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "    74237    0.013    0.000    0.013    0.000 {method 'append' of 'list' objects}\n",
      "      100    0.011    0.000    0.011    0.000 {built-in method torch.stack}\n",
      "    35168    0.010    0.000    0.010    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "    17534    0.009    0.000    0.009    0.000 {built-in method math.cos}\n",
      "      100    0.002    0.000    0.009    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:435(zero_grad)\n",
      "      200    0.001    0.000    0.008    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:491(__enter__)\n",
      "      200    0.000    0.000    0.007    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_ops.py:497(__call__)\n",
      "      200    0.006    0.000    0.006    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "      200    0.006    0.000    0.006    0.000 {built-in method torch._foreach_add_}\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:65(reset)\n",
      "      200    0.005    0.000    0.005    0.000 {built-in method torch._foreach_mul_}\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:58(reset)\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:53(reset)\n",
      "    17634    0.005    0.000    0.005    0.000 {built-in method builtins.iter}\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:112(decorate_context)\n",
      "      100    0.001    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:193(reset)\n",
      "18787/18781    0.004    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "      100    0.001    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:50(_make_grads)\n",
      "    17534    0.004    0.000    0.004    0.000 {built-in method math.sin}\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._foreach_add}\n",
      "      200    0.002    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:495(__exit__)\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._foreach_sqrt}\n",
      "      100    0.000    0.000    0.003    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:228(_cuda_graph_capture_health_check)\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method torch.ones_like}\n",
      "      100    0.002    0.000    0.003    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:20(_group_tensors_by_device_and_dtype)\n",
      "    17934    0.003    0.000    0.003    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'uniform' of 'numpy.random._generator.Generator' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method torch._foreach_addcmul_}\n",
      "      100    0.002    0.000    0.003    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:66(_init_group)\n",
      "      100    0.003    0.000    0.003    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method torch._foreach_addcdiv_}\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method torch._foreach_div_}\n",
      "      100    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:94(is_available)\n",
      "      200    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_ops.py:286(__call__)\n",
      "       10    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
      "      200    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:482(__init__)\n",
      "      800    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:39(_get_value)\n",
      "       20    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:610(write)\n",
      "      200    0.002    0.000    0.002    0.000 {built-in method torch._ops.profiler.}\n",
      "      100    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:489(<listcomp>)\n",
      "      100    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:91(_nvml_based_avail)\n",
      "       20    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:532(_schedule_flush)\n",
      "       10    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:243(schedule)\n",
      "      100    0.000    0.000    0.001    0.000 <frozen os>:773(getenv)\n",
      "       10    0.001    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\zmq\\sugar\\socket.py:545(send)\n",
      "      100    0.000    0.000    0.001    0.000 <frozen _collections_abc>:771(get)\n",
      "      100    0.001    0.000    0.001    0.000 <frozen os>:674(__getitem__)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:494(<listcomp>)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:64(_default_to_fused_or_foreach)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:490(<listcomp>)\n",
      "      300    0.000    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "      416    0.001    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:149(__init__)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\graphs.py:19(is_current_stream_capturing)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:141(clone)\n",
      "      400    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:52(_dispatch_sqrt)\n",
      "      100    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_isCurrentStreamCapturing}\n",
      "     1600    0.001    0.000    0.001    0.000 {built-in method torch.is_complex}\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1039(to)\n",
      "      6/1    0.000    0.000    0.001    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:795(_apply)\n",
      "      200    0.001    0.000    0.001    0.000 C:\\Python311\\Lib\\typing.py:338(inner)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:433(<listcomp>)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:48(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:24(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 <frozen os>:748(encodekey)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:53(__enter__)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1139(convert)\n",
      "      500    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:72(<genexpr>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:27(<lambda>)\n",
      "     1908    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:1102(is_scripting)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:434(<listcomp>)\n",
      "      420    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:942(__hash__)\n",
      "     2123    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:435(<listcomp>)\n",
      "      624    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:57(__exit__)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:436(<listcomp>)\n",
      "      500    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:268(<genexpr>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:87(_is_compiled)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch.zeros_like}\n",
      "      101    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "      100    0.000    0.000    0.000    0.000 <frozen os>:742(check_str)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:492(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:14(__init__)\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:169(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "      400    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:27(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:46(_stack_if_compiling)\n",
      "      416    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "      900    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_utils.py:786(is_compiling)\n",
      "      420    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "      6/1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2269(train)\n",
      "      100    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "      301    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:98(_tensor_or_tensors_to_tuple)\n",
      "      100    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "      122    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\core.py:215(np_random)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:1185(is_alive)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2059(parameters)\n",
      "      100    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2084(named_parameters)\n",
      "       22    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2167(children)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2045(_named_members)\n",
      "      200    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1617(__setattr__)\n",
      "       20    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505(_is_master_process)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:799(compute_should_use_set_data)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:489(add_param_group)\n",
      "       22    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2176(named_children)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\core.py:121(reset)\n",
      "      200    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\jit\\__init__.py:89(annotate)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:1118(_wait_for_tstate_lock)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:249(_optimizer_step_code)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\utils.py:17(maybe_parse_reset_bounds)\n",
      "     21/7    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2224(named_modules)\n",
      "      100    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:127(_event_pipe)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch._has_compatible_shallow_copy_type}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\parameter.py:8(__instancecheck__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._nn._parse_to}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:291(_patch_step_function)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:568(is_set)\n",
      "       20    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2113(<lambda>)\n",
      "       36    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\__future__.py:20(get_overwrite_module_params_on_conversion)\n",
      "        6    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x0000023F4E1E2520}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "def profile_train(model):\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    train_for_profiling(model)\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "    ps.print_stats()\n",
    "    return s.getvalue()\n",
    "\n",
    "profile_output = profile_train(policy)\n",
    "print(profile_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "actor = Actor(n_in=10, n_out=2)\n",
    "critic = Critic(n_in=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=100, lr=LR):\n",
    "    actor_opt = optim.Adam(actor.parameters(), lr=lr)\n",
    "    critic_opt = optim.Adam(critic.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action_probs = actor(torch.from_numpy(state).float())\n",
    "            action = torch.multinomial(action_probs, 1).item()\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            V_current = critic(torch.from_numpy(state).float())\n",
    "            V_next = critic(torch.from_numpy(next_state).float())\n",
    "\n",
    "            # Compute advantage and TD-target\n",
    "            advantage = reward + (1 - int(done)) * V_next - V_current\n",
    "            td_target = reward + (1 - int(done)) * V_next\n",
    "\n",
    "            # Update the critic\n",
    "            critic_loss = advantage.pow(2)\n",
    "            critic_opt.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_opt.step()\n",
    "\n",
    "            # Update the actor\n",
    "            actor_loss = -torch.log(action_probs[action]) * advantage.detach()\n",
    "            actor_opt.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_opt.step()\n",
    "\n",
    "            state = next_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
