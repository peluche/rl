{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U gymnasium\n",
    "# %pip install -U gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REINFORCE â†’ REward Increment = Nonnegative Factor x Offset Reinforcement x Characteristic Eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-4\n",
    "GAMMA = 0.9\n",
    "MAX_STEPS = 1000\n",
    "N_HIDDEN = 32\n",
    "EPS = torch.finfo(torch.float32).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden=N_HIDDEN):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy(n_in=4, n_out=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\t loss: 41.44451904296875\t episode length: 11\n",
      "  100\t loss: 109.17556762695312\t episode length: 23\n",
      "  200\t loss: 70.983642578125\t episode length: 17\n",
      "  300\t loss: 71.39649963378906\t episode length: 17\n",
      "  400\t loss: 80.83428955078125\t episode length: 19\n",
      "  500\t loss: 80.76789093017578\t episode length: 18\n",
      "  600\t loss: 422.9382629394531\t episode length: 72\n",
      "  700\t loss: 130.1358184814453\t episode length: 27\n",
      "  800\t loss: 207.8341827392578\t episode length: 39\n",
      "  900\t loss: 82.06942749023438\t episode length: 18\n",
      " 1000\t loss: 323.978759765625\t episode length: 59\n",
      " 1100\t loss: 149.09169006347656\t episode length: 31\n",
      " 1200\t loss: 141.99850463867188\t episode length: 30\n",
      " 1300\t loss: 814.6326293945312\t episode length: 133\n",
      " 1400\t loss: 522.9898681640625\t episode length: 92\n",
      " 1500\t loss: 95.37647247314453\t episode length: 21\n",
      " 1600\t loss: 142.90773010253906\t episode length: 29\n",
      " 1700\t loss: 264.8891296386719\t episode length: 49\n",
      " 1800\t loss: 116.01841735839844\t episode length: 25\n",
      " 1900\t loss: 738.788330078125\t episode length: 126\n",
      " 2000\t loss: 315.70770263671875\t episode length: 61\n",
      " 2100\t loss: 220.8858642578125\t episode length: 43\n",
      " 2200\t loss: 125.21034240722656\t episode length: 24\n",
      " 2300\t loss: 237.2084197998047\t episode length: 48\n",
      " 2400\t loss: 633.0147705078125\t episode length: 114\n",
      " 2500\t loss: 106.94239044189453\t episode length: 22\n",
      " 2600\t loss: 1356.4422607421875\t episode length: 240\n",
      " 2700\t loss: 915.7734375\t episode length: 163\n",
      " 2800\t loss: 962.935302734375\t episode length: 168\n",
      " 2900\t loss: 1388.9888916015625\t episode length: 246\n",
      " 3000\t loss: 1084.1015625\t episode length: 180\n",
      " 3100\t loss: 660.8934936523438\t episode length: 111\n",
      " 3200\t loss: 1379.9322509765625\t episode length: 239\n",
      " 3300\t loss: 904.7642211914062\t episode length: 165\n",
      " 3400\t loss: 596.8753662109375\t episode length: 105\n",
      " 3500\t loss: 852.5399169921875\t episode length: 158\n",
      " 3600\t loss: 794.8654174804688\t episode length: 144\n",
      " 3700\t loss: 2995.817138671875\t episode length: 532\n",
      " 3800\t loss: 825.9412231445312\t episode length: 150\n",
      " 3900\t loss: 681.861572265625\t episode length: 126\n",
      " 4000\t loss: 1842.671875\t episode length: 323\n",
      " 4100\t loss: 1096.021728515625\t episode length: 197\n",
      " 4200\t loss: 519.9871826171875\t episode length: 97\n",
      " 4300\t loss: 951.2442626953125\t episode length: 182\n",
      " 4400\t loss: 204.35060119628906\t episode length: 40\n",
      " 4500\t loss: 799.5587158203125\t episode length: 146\n",
      " 4600\t loss: 1227.135986328125\t episode length: 222\n",
      " 4700\t loss: 758.5430908203125\t episode length: 144\n",
      " 4800\t loss: 1112.632568359375\t episode length: 195\n",
      " 4900\t loss: 1346.310302734375\t episode length: 246\n",
      " 5000\t loss: 984.9547729492188\t episode length: 183\n",
      " 5100\t loss: 1284.0140380859375\t episode length: 233\n",
      " 5200\t loss: 1712.8182373046875\t episode length: 304\n",
      " 5300\t loss: 848.540283203125\t episode length: 165\n",
      " 5400\t loss: 770.0386962890625\t episode length: 149\n",
      " 5500\t loss: 1361.6966552734375\t episode length: 256\n",
      " 5600\t loss: 1876.152099609375\t episode length: 338\n",
      " 5700\t loss: 1421.895263671875\t episode length: 250\n",
      " 5800\t loss: 1747.5963134765625\t episode length: 313\n",
      " 5900\t loss: 846.3670654296875\t episode length: 149\n",
      " 6000\t loss: 2172.76416015625\t episode length: 379\n",
      " 6100\t loss: 1081.01904296875\t episode length: 208\n",
      " 6200\t loss: 617.15673828125\t episode length: 115\n",
      " 6300\t loss: 764.6069946289062\t episode length: 138\n",
      " 6400\t loss: 1474.4501953125\t episode length: 272\n",
      " 6500\t loss: 775.6671142578125\t episode length: 143\n",
      " 6600\t loss: 837.2587890625\t episode length: 158\n",
      " 6700\t loss: 2005.878662109375\t episode length: 353\n",
      " 6800\t loss: 2723.63427734375\t episode length: 475\n",
      " 6900\t loss: 1953.145263671875\t episode length: 342\n",
      " 7000\t loss: 804.761962890625\t episode length: 140\n",
      " 7100\t loss: 1015.4351806640625\t episode length: 187\n",
      " 7200\t loss: 1546.006103515625\t episode length: 277\n",
      " 7300\t loss: 1569.06005859375\t episode length: 276\n",
      " 7400\t loss: 1461.2388916015625\t episode length: 255\n",
      " 7500\t loss: 1533.527587890625\t episode length: 273\n",
      " 7600\t loss: 1122.80126953125\t episode length: 195\n",
      " 7700\t loss: 1355.7783203125\t episode length: 236\n",
      " 7800\t loss: 913.3783569335938\t episode length: 166\n",
      " 7900\t loss: 638.2809448242188\t episode length: 117\n",
      " 8000\t loss: 2323.3486328125\t episode length: 399\n",
      " 8100\t loss: 1089.30419921875\t episode length: 208\n",
      " 8200\t loss: 1548.672119140625\t episode length: 280\n",
      " 8300\t loss: 1470.887451171875\t episode length: 254\n",
      " 8400\t loss: 932.1563720703125\t episode length: 170\n",
      " 8500\t loss: 1114.94384765625\t episode length: 207\n",
      " 8600\t loss: 1593.6591796875\t episode length: 288\n",
      " 8700\t loss: 2080.31494140625\t episode length: 372\n",
      " 8800\t loss: 935.1983642578125\t episode length: 175\n",
      " 8900\t loss: 2475.8896484375\t episode length: 433\n",
      " 9000\t loss: 996.6414794921875\t episode length: 172\n",
      " 9100\t loss: 2000.5260009765625\t episode length: 376\n",
      " 9200\t loss: 890.7120361328125\t episode length: 162\n",
      " 9300\t loss: 1329.335693359375\t episode length: 247\n",
      " 9400\t loss: 641.1409912109375\t episode length: 110\n",
      " 9500\t loss: 854.837646484375\t episode length: 165\n",
      " 9600\t loss: 1305.0714111328125\t episode length: 237\n",
      " 9700\t loss: 1632.51171875\t episode length: 306\n",
      " 9800\t loss: 747.8028564453125\t episode length: 136\n",
      " 9900\t loss: 1842.588623046875\t episode length: 337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2403a18ebd0>]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def discount_rewards(rewards, gamma):\n",
    "    '''\n",
    "    Compute the discounted rewards backwards through time, e.g.\n",
    "      r0 + gamma * (r1 + gamma * (r2 + gamma * (...)))\n",
    "      [----------------------------------------------]\n",
    "         ^         [---------------------------------]\n",
    "         |           ^           [-------------------]\n",
    "      discount[0]    |             ^           [-----]\n",
    "                  discount[1]      |             ^\n",
    "                                discount[2]      |\n",
    "                                              discount[n]                                              \n",
    "    '''\n",
    "    reward = 0\n",
    "    discounted_rewards = []\n",
    "    for r in rewards[::-1]:\n",
    "        reward = r + gamma * reward\n",
    "        discounted_rewards.append(reward)\n",
    "    return torch.tensor(discounted_rewards[::-1]).to(device)\n",
    "\n",
    "scores = []\n",
    "def train(model, epochs=10, lr=LR, gamma=GAMMA, max_steps=MAX_STEPS, log_every=100):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    opt = optim.Adam(policy.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        rewards, log_probs = [], []\n",
    "        state, _ = env.reset()\n",
    "        # forward pass\n",
    "        for t in range(MAX_STEPS):\n",
    "            # this feel bad performance wise, 1 cycle GPU, 1 cycle CPU\n",
    "            # it's too much context switching\n",
    "            # how can I benchmark this in a notebook?\n",
    "            actions = policy(torch.tensor(state).float().to(device))\n",
    "            action = torch.multinomial(actions, 1)\n",
    "            state, reward, done, _, _ = env.step(action.item())\n",
    "            rewards.append(reward)\n",
    "            log_probs.append(torch.log(actions[action]))\n",
    "            if done:\n",
    "                break\n",
    "        # backward pass\n",
    "        losses = []\n",
    "        discounted_rewards = discount_rewards(rewards, gamma)\n",
    "        normalized_discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + EPS)\n",
    "        for log_prob, reward in zip(log_probs, discounted_rewards):\n",
    "            losses.append(-log_prob * reward)\n",
    "        loss = torch.stack(losses).sum()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch % log_every == 0:\n",
    "            print(f'{epoch:5}\\t loss: {loss.item()}\\t episode length: {t}')\n",
    "        scores.append(t)\n",
    "    model.eval()\n",
    "\n",
    "train(policy, epochs=10000)\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# ----\n",
    "# torch.save(policy.state_dict(), 'weights/cartpole-reinforce-no-normalization.pt')\n",
    "\n",
    "# load\n",
    "# ----\n",
    "# m = Policy(n_in=4, n_out=2).to(device)\n",
    "# m.load_state_dict(torch.load('weights/cartpole-reinforce.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training too long is detrimental ?? wtf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 184 timesteps\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAF/klEQVR4nO3dsY4d1R3A4bPLtfCGoMV2CXJaF7TUVqpILvwalngFly55DRd5BB4BOpQmCZVBiShIFGSDfde+907ewDuz+g14L99X39H5dz/dOXNmTqZpmgYAhE5/6wEAOD7iAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWA3Oy4/PDNl2vOAcARmR2Xl//915pzAHBE3BYDILcoLtM0rTUHAEdkdlym/W5Mh/2aswBwJGbHZf9mOw6712vOAsCRWBCXC3EBYJbZcTm82Y7D7mLNWQA4ErPj8up/P4yL5/9ZcxYAjsT8p8Wmw5imw4qjAHAsnHMBILfsnMt+56wLAJdaFJfdxc9rzQHAEVkUlzevxAWAyy375/LqxRjDbTEA3m5RXH767m9j2HMB4BKL4rJ//cqGPgCX8igyADlxASC3LC7TYexfb1caBYBjsfhjYc66AHCZhXE5jN1WXAB4u0VxOexejxf//sdaswBwJBbvubx5+XylUQA4FpulFzx/8Xw8e/Zs0TXn5+fj1q1bS5cC4JpaHJenT5+OL/76+aJrHj9+PJ48ebJ0KQCuqdlx+WX/4bh5+nK8d3oyTsY0DgsO6jvVD/D7MnvP5eufHo5vf/ls/OHm++PG5r01ZwLgmpsdl4vpg/Fs++n48cZfxtnZH9ecCYBrbuHrX07HnU/+PD786E/rTAPAUfBuMQByi+NyMg7jxAfDAHiLRY8in47duPfBV+N88+Na8wBwBGbHZdp+Pz6++fdxvv/n2B/2a84EwDV3Ms08hLLZ3BgnYxonYxq7/WHRjbEHDx6Mhw8fXnFEAN4ljx49uvQ3s/+57Pe7Kw9y586dce/evStfD8D1svj1L1dx9+7dcf/+/V9jKQDeAR5FBiAnLgDkxAWAnLgAkBMXAHLiAkBOXADIzT7ncvv27SsvcnZ2duVrAbh+Zr/+ZbvdXnmRzWYzNptf5bwmAO+A2XEBgLnsuQCQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDk/g9PjrBPaKgFkwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def show_play(env, policy, max_steps=MAX_STEPS):\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.axis('off')\n",
    "    state, _ = env.reset()\n",
    "    img = ax.imshow(env.render())\n",
    "    for t in range(max_steps):\n",
    "        actions = policy(torch.tensor(state).float().to(device))\n",
    "        action = actions.argmax()\n",
    "        state, _, done, _, _ = env.step(action.item())\n",
    "        img.set_data(env.render())\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t + 1))\n",
    "            break\n",
    "\n",
    "show_play(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the code in a bunch of functions to make the cProfile easier to read\n",
    "\n",
    "def gpu_world(model, arg):\n",
    "    return model(arg)\n",
    "\n",
    "def cpu_world_simulate_env(env, action):\n",
    "    return env.step(action.item())\n",
    "\n",
    "def cpu_world_get_action(actions, log_probs):\n",
    "    # Categorical seems dog slow\n",
    "    # --------------------------\n",
    "    # m = torch.distributions.Categorical(actions)\n",
    "    # action = m.sample()\n",
    "    # log_probs.append(m.log_prob(action))\n",
    "\n",
    "    # multinormal is faster\n",
    "    # ---------------------\n",
    "    action = torch.multinomial(actions, 1)\n",
    "    log_probs.append(torch.log(actions[action]))\n",
    "\n",
    "    # but they should be equivalent\n",
    "    # -----------------------------\n",
    "    # assert m.log_prob(action) - torch.log(actions[action]) < 0.001\n",
    "\n",
    "    return action\n",
    "\n",
    "def cpu_world_sample(rewards, log_probs, env, actions):\n",
    "    action = cpu_world_get_action(actions, log_probs)\n",
    "\n",
    "    state, reward, done, _, _ = cpu_world_simulate_env(env, action)\n",
    "    rewards.append(reward)\n",
    "    return state, done\n",
    "\n",
    "def cpu_world_backward_pass(rewards, log_probs, gamma):\n",
    "    losses = []\n",
    "    discounted_rewards = discount_rewards(rewards, gamma)\n",
    "    normalized_discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + EPS)\n",
    "    for log_prob, reward in zip(log_probs, normalized_discounted_rewards):\n",
    "        losses.append(-log_prob * reward)\n",
    "    return losses\n",
    "\n",
    "def gpu_world_backward_pass(losses, opt):\n",
    "    loss = torch.stack(losses).to(device).sum()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss\n",
    "\n",
    "def train_for_profiling(model, epochs=100, lr=LR, gamma=GAMMA, max_steps=MAX_STEPS):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    opt = optim.Adam(policy.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        rewards, log_probs = [], []\n",
    "        state, _ = env.reset()\n",
    "        # forward pass\n",
    "        for _ in range(MAX_STEPS):\n",
    "            actions = gpu_world(policy, torch.tensor(state).float().to(device))\n",
    "            state, done = cpu_world_sample(rewards, log_probs, env, actions)\n",
    "            if done: break\n",
    "        # backward pass\n",
    "        losses = cpu_world_backward_pass(rewards, log_probs, gamma)\n",
    "        loss = gpu_world_backward_pass(losses, opt)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'{epoch:5} {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 -1.0809001922607422\n",
      "   10 1.9035100936889648\n",
      "   20 -0.7205734252929688\n",
      "   30 -0.15667247772216797\n",
      "   40 -2.5725440979003906\n",
      "   50 1.4350948333740234\n",
      "   60 -41.44963836669922\n",
      "   70 0.5656423568725586\n",
      "   80 -11.336851119995117\n",
      "   90 -2.0969085693359375\n",
      "         1519648 function calls (1391183 primitive calls) in 26.023 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.436    0.436   26.023   26.023 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:65(train_for_profiling)\n",
      "      100    0.002    0.000    9.703    0.097 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:58(gpu_world_backward_pass)\n",
      "      100    0.001    0.000    9.604    0.096 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:428(backward)\n",
      "      100    0.001    0.000    9.603    0.096 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:106(backward)\n",
      "      100    9.597    0.096    9.597    0.096 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "    25687    0.048    0.000    6.273    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:43(cpu_world_sample)\n",
      "    25687    0.028    0.000    6.190    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:3(gpu_world)\n",
      "154122/25687    0.317    0.000    6.162    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1494(_call_impl)\n",
      "    25687    0.062    0.000    6.058    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\1237419200.py:11(forward)\n",
      "    25687    0.261    0.000    5.909    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215(forward)\n",
      "    25687    2.648    0.000    3.875    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:9(cpu_world_get_action)\n",
      "    51374    0.164    0.000    3.818    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:113(forward)\n",
      "    51374    3.592    0.000    3.592    0.000 {built-in method torch._C._nn.linear}\n",
      "    25687    0.036    0.000    2.347    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:6(cpu_world_simulate_env)\n",
      "    25895    2.021    0.000    2.021    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "    26497    1.800    0.000    1.800    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "      100    0.910    0.009    0.968    0.010 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\798756395.py:50(cpu_world_backward_pass)\n",
      "    25687    0.026    0.000    0.754    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:102(forward)\n",
      "    25687    0.028    0.000    0.728    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1446(relu)\n",
      "    25687    0.692    0.000    0.692    0.000 {built-in method torch.relu}\n",
      "    25687    0.025    0.000    0.682    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1481(forward)\n",
      "    25687    0.033    0.000    0.657    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1813(softmax)\n",
      "    25687    0.633    0.000    0.633    0.000 {built-in method torch.log}\n",
      "    25687    0.617    0.000    0.617    0.000 {method 'softmax' of 'torch._C._TensorBase' objects}\n",
      "    20613    0.521    0.000    0.521    0.000 {method 'argmax' of 'torch._C._TensorBase' objects}\n",
      "    25687    0.038    0.000    0.513    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:46(step)\n",
      "    25687    0.016    0.000    0.474    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:52(step)\n",
      "    25687    0.021    0.000    0.458    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:45(step)\n",
      "    25687    0.213    0.000    0.437    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:132(step)\n",
      "    25791    0.415    0.000    0.415    0.000 {built-in method torch.tensor}\n",
      "   154222    0.201    0.000    0.201    0.000 {built-in method torch._C._get_tracing_state}\n",
      "    25687    0.119    0.000    0.125    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\spaces\\discrete.py:94(contains)\n",
      "   128435    0.096    0.000    0.096    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1601(__getattr__)\n",
      "    25787    0.080    0.000    0.080    0.000 {built-in method numpy.array}\n",
      "      100    0.003    0.000    0.062    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:265(wrapper)\n",
      "     5074    0.062    0.000    0.062    0.000 {built-in method torch.randint}\n",
      "      100    0.001    0.000    0.051    0.001 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:29(_use_grad)\n",
      "      100    0.001    0.000    0.049    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:108(step)\n",
      "      100    0.002    0.000    0.042    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:231(adam)\n",
      "      100    0.003    0.000    0.039    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:396(_multi_tensor_adam)\n",
      "    25687    0.020    0.000    0.031    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:207(__iter__)\n",
      "      100    0.000    0.000    0.025    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:920(__iter__)\n",
      "      100    0.024    0.000    0.024    0.000 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "      100    0.023    0.000    0.023    0.000 {built-in method torch.stack}\n",
      "    25687    0.023    0.000    0.023    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "      100    0.007    0.000    0.022    0.000 C:\\Users\\p\\AppData\\Local\\Temp\\ipykernel_22632\\3126631963.py:1(discount_rewards)\n",
      "   106849    0.018    0.000    0.018    0.000 {method 'append' of 'list' objects}\n",
      "    51474    0.015    0.000    0.015    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "    25687    0.013    0.000    0.013    0.000 {built-in method math.cos}\n",
      "      100    0.003    0.000    0.009    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:435(zero_grad)\n",
      "      200    0.001    0.000    0.008    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:491(__enter__)\n",
      "      200    0.000    0.000    0.007    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_ops.py:497(__call__)\n",
      "    25787    0.007    0.000    0.007    0.000 {built-in method builtins.iter}\n",
      "      200    0.007    0.000    0.007    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "      200    0.007    0.000    0.007    0.000 {built-in method torch._foreach_add_}\n",
      "    25687    0.006    0.000    0.006    0.000 {built-in method math.sin}\n",
      "26940/26934    0.006    0.000    0.006    0.000 {built-in method builtins.isinstance}\n",
      "      200    0.005    0.000    0.005    0.000 {built-in method torch._foreach_mul_}\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:65(reset)\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:58(reset)\n",
      "      100    0.000    0.000    0.005    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:53(reset)\n",
      "      100    0.001    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:50(_make_grads)\n",
      "      100    0.001    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:193(reset)\n",
      "      100    0.000    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:112(decorate_context)\n",
      "    26087    0.004    0.000    0.004    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "      200    0.002    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:495(__exit__)\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._foreach_add}\n",
      "    25687    0.004    0.000    0.004    0.000 {method 'random' of '_random.Random' objects}\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch.ones_like}\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._foreach_sqrt}\n",
      "      100    0.000    0.000    0.004    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:228(_cuda_graph_capture_health_check)\n",
      "      100    0.003    0.000    0.003    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
      "      100    0.002    0.000    0.003    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:20(_group_tensors_by_device_and_dtype)\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method torch._foreach_addcdiv_}\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method torch._foreach_addcmul_}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'std' of 'torch._C._TensorBase' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'uniform' of 'numpy.random._generator.Generator' objects}\n",
      "       10    0.000    0.000    0.003    0.000 {built-in method builtins.print}\n",
      "       20    0.000    0.000    0.003    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:610(write)\n",
      "      100    0.002    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:66(_init_group)\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method torch._foreach_div_}\n",
      "      100    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:94(is_available)\n",
      "       20    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:532(_schedule_flush)\n",
      "       10    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:243(schedule)\n",
      "      200    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_ops.py:286(__call__)\n",
      "       10    0.002    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\zmq\\sugar\\socket.py:545(send)\n",
      "      200    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:482(__init__)\n",
      "      100    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:489(<listcomp>)\n",
      "      200    0.002    0.000    0.002    0.000 {built-in method torch._ops.profiler.}\n",
      "      800    0.001    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:39(_get_value)\n",
      "      100    0.000    0.000    0.002    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:91(_nvml_based_avail)\n",
      "      100    0.000    0.000    0.001    0.000 <frozen os>:773(getenv)\n",
      "      100    0.000    0.000    0.001    0.000 <frozen _collections_abc>:771(get)\n",
      "      100    0.001    0.000    0.001    0.000 <frozen os>:674(__getitem__)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:494(<listcomp>)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:64(_default_to_fused_or_foreach)\n",
      "      416    0.001    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:149(__init__)\n",
      "      400    0.001    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:52(_dispatch_sqrt)\n",
      "      300    0.000    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\graphs.py:19(is_current_stream_capturing)\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:490(<listcomp>)\n",
      "      100    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_isCurrentStreamCapturing}\n",
      "      100    0.000    0.000    0.001    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:141(clone)\n",
      "     1600    0.001    0.000    0.001    0.000 {built-in method torch.is_complex}\n",
      "      200    0.001    0.000    0.001    0.000 C:\\Python311\\Lib\\typing.py:338(inner)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:433(<listcomp>)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:48(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 <frozen os>:748(encodekey)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:24(<listcomp>)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:53(__enter__)\n",
      "      500    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:72(<genexpr>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:27(<lambda>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:434(<listcomp>)\n",
      "     2123    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "      420    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_tensor.py:942(__hash__)\n",
      "     1908    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:1102(is_scripting)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:435(<listcomp>)\n",
      "      108    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:57(__exit__)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:436(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:87(_is_compiled)\n",
      "      500    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:268(<genexpr>)\n",
      "      624    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1039(to)\n",
      "      101    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "      6/1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:795(_apply)\n",
      "      100    0.000    0.000    0.000    0.000 <frozen os>:742(check_str)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:492(<listcomp>)\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch.zeros_like}\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "      400    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\utils\\_foreach_utils.py:27(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:46(_stack_if_compiling)\n",
      "      416    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "      900    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\_utils.py:786(is_compiling)\n",
      "      420    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:14(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:169(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:98(_tensor_or_tensors_to_tuple)\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
      "      301    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\core.py:215(np_random)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:1185(is_alive)\n",
      "      122    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "      6/1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2269(train)\n",
      "      200    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "       20    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505(_is_master_process)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2059(parameters)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2084(named_parameters)\n",
      "       22    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2167(children)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1139(convert)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\core.py:121(reset)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2045(_named_members)\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1617(__setattr__)\n",
      "      200    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\jit\\__init__.py:89(annotate)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\utils.py:17(maybe_parse_reset_bounds)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:1118(_wait_for_tstate_lock)\n",
      "       22    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2176(named_children)\n",
      "      100    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:489(add_param_group)\n",
      "      100    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:249(_optimizer_step_code)\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:127(_event_pipe)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:799(compute_should_use_set_data)\n",
      "     21/7    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2224(named_modules)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\parameter.py:8(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._nn._parse_to}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "       20    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Python311\\Lib\\threading.py:568(is_set)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch._has_compatible_shallow_copy_type}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:291(_patch_step_function)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2113(<lambda>)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\__future__.py:20(get_overwrite_module_params_on_conversion)\n",
      "        6    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x0000023F4E1E2520}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "def profile_train(model):\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    train_for_profiling(model)\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "    ps.print_stats()\n",
    "    return s.getvalue()\n",
    "\n",
    "profile_output = profile_train(policy)\n",
    "print(profile_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "actor = Actor(n_in=10, n_out=2)\n",
    "critic = Critic(n_in=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=100, lr=LR):\n",
    "    actor_opt = optim.Adam(actor.parameters(), lr=lr)\n",
    "    critic_opt = optim.Adam(critic.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action_probs = actor(torch.from_numpy(state).float())\n",
    "            action = torch.multinomial(action_probs, 1).item()\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            V_current = critic(torch.from_numpy(state).float())\n",
    "            V_next = critic(torch.from_numpy(next_state).float())\n",
    "\n",
    "            # Compute advantage and TD-target\n",
    "            advantage = reward + (1 - int(done)) * V_next - V_current\n",
    "            td_target = reward + (1 - int(done)) * V_next\n",
    "\n",
    "            # Update the critic\n",
    "            critic_loss = advantage.pow(2)\n",
    "            critic_opt.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_opt.step()\n",
    "\n",
    "            # Update the actor\n",
    "            actor_loss = -torch.log(action_probs[action]) * advantage.detach()\n",
    "            actor_opt.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_opt.step()\n",
    "\n",
    "            state = next_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
